{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating a pair RDD\n",
    "trafficpath = \"file:///home/shubham/Downloads/nayadata/Dodgers.data\"\n",
    "gamespath = \"file:///home/shubham/Downloads/nayadata/Dodgers.events\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an RDD\n",
    "traffic = sc.textFile(trafficpath)\n",
    "traffic.take(10)\n",
    "\n",
    "#As we can see there's a slice of 05 minutes and the second column depicts number of cars passed by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = sc.textFile(gamespath)\n",
    "games.take(10)\n",
    "#We have start and end time for a game\n",
    "#We also have audiences, opponents, Win/Loss with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "from StringIO import StringIO\n",
    "\n",
    "#We will setup a function to make a tuple of two elements i.e. data and 5 minute time slice\n",
    "\n",
    "def parsetraffic(row):\n",
    "    date_fmt= \"%m/%d/%Y %H:%M\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],date_fmt)\n",
    "    row[1] = int(row[1])\n",
    "    return (row[0],row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficparsed = traffic.map(parsetraffic)\n",
    "#trafficparsed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficparsed.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summerazing a pair RDD\n",
    "#Each date occurs multiple times & thus values need to be sum\n",
    "dailytrend = trafficparsed.map(lambda x:(x[0].date(), x[1]))\\\n",
    "                        .reduceByKey(lambda x,y:x+y) #This will return a RDD where each record is date \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytrend.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now to sort the data by the values and see which are the days on which we had maximum traffic\n",
    "\n",
    "dailytrend.sortBy(lambda x:-x[1]).take(10)\n",
    "\n",
    "#TO get our data sorted in descending order we hab=ve to take negative of total number of cars\n",
    "#With top 10 records we can see that we have the date with maximum traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now it will be interesting to see whether the most traffic days had games or not on that particular day\n",
    "#To do this we need to murge our dataset that has dates of games & for that we need a join operation\n",
    "\n",
    "#Joining with games\n",
    "\n",
    "def parsegames(row):\n",
    "    date_fmt = \"%m/%d/%y\"\n",
    "    row = row.split(\",\")\n",
    "    row[0] = datetime.strptime(row[0],date_fmt).date()\n",
    "    return (row[0],row[4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gamesparsed = games.map(parsegames)\n",
    "#gamesparsed.first()\n",
    "#print(gamesparsed)\n",
    "#gamesparsed.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamesparsed.first()\n",
    "gamesparsed.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Joining RDD with our original RDD\n",
    "\n",
    "dailytrendcombined = dailytrend.leftOuterJoin(gamesparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytrendcombined.take(10)\n",
    "\n",
    "#Key is still a date but the value is now a tuple which contains values from 1st RDD & 2nd RDD.\n",
    "#Whenever there's no match for 2nd RDD we have its corresponding value as None\n",
    "#the reason to choose left outer join so that we can keep all dates in our dataset whether or not there's a game that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function will take each record, convert it into a tuple of 4 elements i.e. Date, Oponent, Type of Day, No. of cars\n",
    "\n",
    "def checkgameday(row):\n",
    "    if row[1][1] == None:\n",
    "        return (row[0],row[1][1],\"Regular Day\",row[1][0])\n",
    "    else:\n",
    "        return (row[0],row[1][1],\"Game Day\",row[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dailytrendbygames = dailytrendcombined.map(checkgameday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailytrendbygames.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to use sort by operation again but this time sorting by the forth value each time in each record.\n",
    "\n",
    "dailytrendbygames.sortBy(lambda x: -x[3]).take(10)\n",
    "\n",
    "#Now we have top 10days of traffic with game held or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we need to see the average traffic on days with game and without game for this we need \n",
    "#A combined by key operation\n",
    "\n",
    "#Basically a 'CombinedByKey' consist of three functions i.e. create combiner function, Merge function & MergeCombiner function.\n",
    "\n",
    "#Create Combiner Function : Initializes a value when a key is seen for the first time within a partition.\n",
    "#Merge Function : Specifies how values with the smekeyshould be combined for each record which are present within a single partition\n",
    "#The result from each partition are then combined using a 'MergeCombiner Function'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average on Game day vs Non-Game Day\n",
    "\n",
    "dailytrendbygames.map(lambda x:(x[2],x[3]))\\\n",
    "                .combineByKey(lambda value : (value, 1),\\\n",
    "            lambda acc,value:(acc[0]+value,acc[1]+1),\\\n",
    "            lambda acc1,acc2:(acc1[0]+acc2[0],acc1[1]+acc2[1]))\\\n",
    "            .mapValues(lambda x:x[0]/x[1])\\\n",
    "            .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
